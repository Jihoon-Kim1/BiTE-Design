{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIM1Ag8MbBFx"
      },
      "source": [
        "# Final Candidate Analysis\n",
        "## BiTE Rigid Linker - 최종 후보 분석\n",
        "\n",
        "### 필요한 파일\n",
        "```\n",
        "/content/\n",
        "├── reference.pdb                              ← ColabFold PDB\n",
        "├── predictions/                               ← 외부 AlphaFold2 결과\n",
        "│   ├── *_relaxed_rank_001.pdb\n",
        "│   ├── *_relaxed_rank_002.pdb\n",
        "│   ├── ...\n",
        "│   ├── *_scores_rank_001.json                 ← pLDDT/PAE 데이터\n",
        "│   └── ...\n",
        "└── Include_antigen_with_perfect_distance.pdb  ← 항원-항체 복합체\n",
        "```\n",
        "\n",
        "### 분석 항목\n",
        "| 항목 | 설명 | 출처 |\n",
        "|------|------|------|\n",
        "| RMSD | Reference와의 구조 차이 | PDB |\n",
        "| Antigen Distance | CD3e-HER2 거리 (목표: 130Å) | PDB |\n",
        "| pTM, pLDDT | 구조 예측 신뢰도 | JSON |\n",
        "| PAE | 도메인 간 오차 예측 | JSON |\n",
        "| NMA | 유연성/강성 분석 | PDB |\n",
        "\n",
        "### 출력\n",
        "- **모든 메트릭을 컬럼으로 하는 전체 테이블**\n",
        "- CSV 파일 저장\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wzq4vzwobBFy"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# CELL 1: RMSD ANALYSIS FUNCTIONS\n",
        "# ================================================================================\n",
        "\n",
        "#@title **Cell 1: Load RMSD Analysis Functions** { display-mode: \"form\" }\n",
        "#@markdown This cell loads all core functions for RMSD calculation.\n",
        "\n",
        "# --- Package Installation ---\n",
        "!pip install biopython --quiet\n",
        "\n",
        "# --- Imports ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from Bio.PDB import PDBParser, Superimposer, PPBuilder\n",
        "from Bio.PDB.Atom import Atom\n",
        "from Bio.PDB.Residue import Residue\n",
        "from Bio.PDB.Polypeptide import is_aa\n",
        "\n",
        "# --- Constants ---\n",
        "SCFV1_LENGTH = 240  # First scFv domain length\n",
        "SCFV2_LENGTH = 242  # Second scFv domain length\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 1: Loading RMSD Analysis Functions\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# CORE FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def get_ca_atoms(residues: List[Residue]) -> List[Atom]:\n",
        "    \"\"\"Extract CA atoms from residues.\"\"\"\n",
        "    ca_atoms = []\n",
        "    for res in residues:\n",
        "        if 'CA' in res:\n",
        "            ca_atoms.append(res['CA'])\n",
        "    return ca_atoms\n",
        "\n",
        "\n",
        "def extract_residues(structure) -> List[Residue]:\n",
        "    \"\"\"Extract all amino acid residues from a structure.\"\"\"\n",
        "    residues = []\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            for residue in chain:\n",
        "                if is_aa(residue, standard=True):\n",
        "                    residues.append(residue)\n",
        "    return residues\n",
        "\n",
        "\n",
        "def align_and_calculate_rmsd(\n",
        "    ref_atoms: List[Atom],\n",
        "    target_atoms: List[Atom],\n",
        "    full_target_atoms: List[Atom] = None\n",
        ") -> Tuple[float, List[Atom]]:\n",
        "    \"\"\"Align target atoms to reference atoms and calculate RMSD.\"\"\"\n",
        "    if len(ref_atoms) != len(target_atoms):\n",
        "        raise ValueError(f\"Atom count mismatch: ref={len(ref_atoms)}, target={len(target_atoms)}\")\n",
        "\n",
        "    if len(ref_atoms) == 0:\n",
        "        raise ValueError(\"No atoms to align\")\n",
        "\n",
        "    sup = Superimposer()\n",
        "    sup.set_atoms(ref_atoms, target_atoms)\n",
        "\n",
        "    if full_target_atoms is not None:\n",
        "        sup.apply(full_target_atoms)\n",
        "    else:\n",
        "        sup.apply(target_atoms)\n",
        "\n",
        "    return sup.rms, target_atoms\n",
        "\n",
        "\n",
        "def calculate_rmsd_only(atoms1: List[Atom], atoms2: List[Atom]) -> float:\n",
        "    \"\"\"Calculate RMSD between two sets of atoms without alignment.\"\"\"\n",
        "    if len(atoms1) != len(atoms2):\n",
        "        raise ValueError(f\"Atom count mismatch: {len(atoms1)} vs {len(atoms2)}\")\n",
        "\n",
        "    coords1 = np.array([atom.get_coord() for atom in atoms1])\n",
        "    coords2 = np.array([atom.get_coord() for atom in atoms2])\n",
        "\n",
        "    diff = coords1 - coords2\n",
        "    rmsd = np.sqrt(np.mean(np.sum(diff**2, axis=1)))\n",
        "\n",
        "    return rmsd\n",
        "\n",
        "\n",
        "def load_reference_structure(ref_path: str) -> Tuple[List[Atom], List[Atom]]:\n",
        "    \"\"\"Load reference structure and extract scFv1 and scFv2 CA atoms.\"\"\"\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    ref_structure = parser.get_structure('reference', ref_path)\n",
        "    ref_residues = extract_residues(ref_structure)\n",
        "\n",
        "    total_residues = len(ref_residues)\n",
        "    print(f\"Reference structure: {total_residues} residues\")\n",
        "\n",
        "    if total_residues < SCFV1_LENGTH + SCFV2_LENGTH:\n",
        "        raise ValueError(f\"Reference structure too short: {total_residues} residues\")\n",
        "\n",
        "    ref_scfv1 = ref_residues[:SCFV1_LENGTH]\n",
        "    ref_scfv2 = ref_residues[-SCFV2_LENGTH:]\n",
        "\n",
        "    ref_scfv1_ca = get_ca_atoms(ref_scfv1)\n",
        "    ref_scfv2_ca = get_ca_atoms(ref_scfv2)\n",
        "\n",
        "    print(f\"  • scFv1: {len(ref_scfv1_ca)} CA atoms\")\n",
        "    print(f\"  • scFv2: {len(ref_scfv2_ca)} CA atoms\")\n",
        "\n",
        "    return ref_scfv1_ca, ref_scfv2_ca\n",
        "\n",
        "\n",
        "def analyze_single_target(\n",
        "    ref_scfv1_ca: List[Atom],\n",
        "    ref_scfv2_ca: List[Atom],\n",
        "    target_path: str\n",
        ") -> Dict:\n",
        "    \"\"\"Analyze a single target structure against reference domains.\"\"\"\n",
        "    result = {\n",
        "        'Filename': Path(target_path).name,\n",
        "        'Status': 'Failed',\n",
        "        'Total_Residues': 0,\n",
        "        'Linker_Length': 0,\n",
        "        'scFv1_RMSD': None,\n",
        "        'scFv2_RMSD': None,\n",
        "        'Avg_RMSD': None,\n",
        "        'Final_RMSD': None,\n",
        "        'Best_Alignment': None,\n",
        "        'Error': None\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        parser = PDBParser(QUIET=True)\n",
        "        target_structure = parser.get_structure('target', target_path)\n",
        "        target_residues = extract_residues(target_structure)\n",
        "\n",
        "        total_residues = len(target_residues)\n",
        "        result['Total_Residues'] = total_residues\n",
        "\n",
        "        if total_residues < SCFV1_LENGTH + SCFV2_LENGTH:\n",
        "            result['Error'] = f\"Too few residues: {total_residues}\"\n",
        "            return result\n",
        "\n",
        "        linker_length = total_residues - SCFV1_LENGTH - SCFV2_LENGTH\n",
        "        result['Linker_Length'] = linker_length\n",
        "\n",
        "        target_scfv1 = target_residues[:SCFV1_LENGTH]\n",
        "        target_scfv2 = target_residues[-SCFV2_LENGTH:]\n",
        "\n",
        "        target_scfv1_ca = get_ca_atoms(target_scfv1)\n",
        "        target_scfv2_ca = get_ca_atoms(target_scfv2)\n",
        "        target_all_ca = get_ca_atoms(target_residues)\n",
        "\n",
        "        if len(target_scfv1_ca) != len(ref_scfv1_ca):\n",
        "            result['Error'] = f\"scFv1 atom mismatch: {len(target_scfv1_ca)} vs {len(ref_scfv1_ca)}\"\n",
        "            return result\n",
        "        if len(target_scfv2_ca) != len(ref_scfv2_ca):\n",
        "            result['Error'] = f\"scFv2 atom mismatch: {len(target_scfv2_ca)} vs {len(ref_scfv2_ca)}\"\n",
        "            return result\n",
        "\n",
        "        # Align on scFv1\n",
        "        rmsd_scfv1, _ = align_and_calculate_rmsd(ref_scfv1_ca, target_scfv1_ca, target_all_ca)\n",
        "        aligned_scfv2_ca = get_ca_atoms(target_residues[-SCFV2_LENGTH:])\n",
        "        rmsd_scfv2_after_scfv1_align = calculate_rmsd_only(ref_scfv2_ca, aligned_scfv2_ca)\n",
        "\n",
        "        # Reload for fresh coordinates\n",
        "        parser2 = PDBParser(QUIET=True)\n",
        "        target_structure2 = parser2.get_structure('target2', target_path)\n",
        "        target_residues2 = extract_residues(target_structure2)\n",
        "        target_scfv2_ca_2 = get_ca_atoms(target_residues2[-SCFV2_LENGTH:])\n",
        "        target_all_ca_2 = get_ca_atoms(target_residues2)\n",
        "\n",
        "        # Align on scFv2\n",
        "        rmsd_scfv2, _ = align_and_calculate_rmsd(ref_scfv2_ca, target_scfv2_ca_2, target_all_ca_2)\n",
        "        aligned_scfv1_ca = get_ca_atoms(target_residues2[:SCFV1_LENGTH])\n",
        "        rmsd_scfv1_after_scfv2_align = calculate_rmsd_only(ref_scfv1_ca, aligned_scfv1_ca)\n",
        "\n",
        "        avg_rmsd_align_scfv1 = (rmsd_scfv1 + rmsd_scfv2_after_scfv1_align) / 2\n",
        "        avg_rmsd_align_scfv2 = (rmsd_scfv2 + rmsd_scfv1_after_scfv2_align) / 2\n",
        "\n",
        "        if avg_rmsd_align_scfv1 <= avg_rmsd_align_scfv2:\n",
        "            result['Final_RMSD'] = rmsd_scfv2_after_scfv1_align\n",
        "            result['Best_Alignment'] = 'scFv1'\n",
        "            result['scFv1_RMSD'] = rmsd_scfv1\n",
        "            result['scFv2_RMSD'] = rmsd_scfv2_after_scfv1_align\n",
        "        else:\n",
        "            result['Final_RMSD'] = rmsd_scfv1_after_scfv2_align\n",
        "            result['Best_Alignment'] = 'scFv2'\n",
        "            result['scFv1_RMSD'] = rmsd_scfv1_after_scfv2_align\n",
        "            result['scFv2_RMSD'] = rmsd_scfv2\n",
        "\n",
        "        result['Avg_RMSD'] = min(avg_rmsd_align_scfv1, avg_rmsd_align_scfv2)\n",
        "        result['Status'] = 'Success'\n",
        "\n",
        "    except Exception as e:\n",
        "        result['Error'] = str(e)\n",
        "\n",
        "    return result\n",
        "\n",
        "# =============================================================================\n",
        "# SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(\"✓ Functions loaded successfully!\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"\\nDomain structure:\")\n",
        "print(f\"  • scFv1: {SCFV1_LENGTH} residues (N-terminal)\")\n",
        "print(f\"  • scFv2: {SCFV2_LENGTH} residues (C-terminal)\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V7JbGmAbBF0"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# CELL 2: RMSD ANALYSIS (ColabFold vs External AlphaFold2)\n",
        "# ================================================================================\n",
        "\n",
        "#@title **Cell 2: RMSD Comparison** { display-mode: \"form\" }\n",
        "#@markdown ### Configuration\n",
        "#@markdown **Reference:** ColabFold에서 얻은 PDB (1개)\n",
        "REFERENCE_PATH = \"/content/reference.pdb\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Predictions:** 외부 AlphaFold2에서 얻은 relaxed PDB들 (5개)\n",
        "PREDICTIONS_FOLDER = \"/content/predictions/\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Requires:** Cell 1 must be run first.\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 2: RMSD Analysis (ColabFold vs External AlphaFold2)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# VALIDATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n--- Validation ---\")\n",
        "\n",
        "if not Path(REFERENCE_PATH).exists():\n",
        "    raise FileNotFoundError(f\"Reference file not found: {REFERENCE_PATH}\")\n",
        "print(f\"✓ Reference: {REFERENCE_PATH}\")\n",
        "\n",
        "pred_folder = Path(PREDICTIONS_FOLDER)\n",
        "if not pred_folder.exists():\n",
        "    raise FileNotFoundError(f\"Predictions folder not found: {PREDICTIONS_FOLDER}\")\n",
        "\n",
        "pdb_files = sorted(pred_folder.glob(\"*.pdb\"))\n",
        "if not pdb_files:\n",
        "    raise FileNotFoundError(f\"No PDB files found in {PREDICTIONS_FOLDER}\")\n",
        "print(f\"✓ Found {len(pdb_files)} prediction PDB files\")\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD REFERENCE & ANALYZE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"LOADING REFERENCE STRUCTURE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "ref_scfv1, ref_scfv2 = load_reference_structure(REFERENCE_PATH)\n",
        "\n",
        "# Also get reference info\n",
        "parser = PDBParser(QUIET=True)\n",
        "ref_structure = parser.get_structure('ref', REFERENCE_PATH)\n",
        "ref_residues = extract_residues(ref_structure)\n",
        "ref_linker_length = len(ref_residues) - SCFV1_LENGTH - SCFV2_LENGTH\n",
        "\n",
        "print(f\"  • Linker length: {ref_linker_length} residues\")\n",
        "print(f\"  • Total length: {len(ref_residues)} residues\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANALYZING PREDICTIONS vs REFERENCE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, pdb_file in enumerate(pdb_files, 1):\n",
        "    print(f\"\\n  [{i}/{len(pdb_files)}] {pdb_file.name}\", end=\"\")\n",
        "\n",
        "    result = analyze_single_target(ref_scfv1, ref_scfv2, str(pdb_file))\n",
        "    result['PDB_Path'] = str(pdb_file)\n",
        "\n",
        "    if result['Status'] == 'Success':\n",
        "        print(f\" → RMSD: {result['Final_RMSD']:.4f} Å ({result['Best_Alignment']})\")\n",
        "    else:\n",
        "        print(f\" → FAILED: {result['Error']}\")\n",
        "\n",
        "    results.append(result)\n",
        "\n",
        "# Create DataFrame\n",
        "rmsd_df = pd.DataFrame(results)\n",
        "\n",
        "# =============================================================================\n",
        "# DISPLAY RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"RMSD RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "display_df = rmsd_df.copy()\n",
        "display_df['Final_RMSD'] = display_df['Final_RMSD'].apply(\n",
        "    lambda x: f\"{x:.4f}\" if pd.notna(x) else \"N/A\"\n",
        ")\n",
        "display_df['scFv1_RMSD'] = display_df['scFv1_RMSD'].apply(\n",
        "    lambda x: f\"{x:.4f}\" if pd.notna(x) else \"N/A\"\n",
        ")\n",
        "display_df['scFv2_RMSD'] = display_df['scFv2_RMSD'].apply(\n",
        "    lambda x: f\"{x:.4f}\" if pd.notna(x) else \"N/A\"\n",
        ")\n",
        "\n",
        "display_cols = ['Filename', 'Final_RMSD', 'scFv1_RMSD', 'scFv2_RMSD', 'Best_Alignment']\n",
        "print(display_df[display_cols].to_string(index=False))\n",
        "\n",
        "# Statistics\n",
        "successful = rmsd_df[rmsd_df['Status'] == 'Success']\n",
        "if len(successful) > 0:\n",
        "    print(f\"\\nStatistics:\")\n",
        "    print(f\"  • Mean RMSD: {successful['Final_RMSD'].mean():.4f} Å\")\n",
        "    print(f\"  • Std RMSD:  {successful['Final_RMSD'].std():.4f} Å\")\n",
        "    print(f\"  • Min RMSD:  {successful['Final_RMSD'].min():.4f} Å\")\n",
        "    print(f\"  • Max RMSD:  {successful['Final_RMSD'].max():.4f} Å\")\n",
        "\n",
        "# Store for later cells\n",
        "comparison_df = rmsd_df.copy()\n",
        "comparison_df['Jobname'] = comparison_df['Filename'].apply(lambda x: x.replace('.pdb', ''))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ Cell 2 Complete\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nData saved to: rmsd_df, comparison_df ({len(rmsd_df)} rows)\")\n",
        "print(\"→ Run Cell 3 for NMA analysis\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bngi58mgbBF0"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# CELL 3: NORMAL MODE ANALYSIS (NMA)\n",
        "# ================================================================================\n",
        "\n",
        "#@title **Cell 3: Normal Mode Analysis (NMA)** { display-mode: \"form\" }\n",
        "#@markdown ### NMA Parameters\n",
        "GNM_CUTOFF = 10.0  #@param {type:\"number\"}\n",
        "ANM_CUTOFF = 15.0  #@param {type:\"number\"}\n",
        "N_MODES = 20  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Requires:** Cell 2 must be run first.\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 3: Normal Mode Analysis (NMA)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Install ProDy\n",
        "try:\n",
        "    import prody\n",
        "    from prody import *\n",
        "except ImportError:\n",
        "    print(\"Installing ProDy...\")\n",
        "    import subprocess\n",
        "    subprocess.run(['pip', 'install', '-q', 'prody'], capture_output=True)\n",
        "    import prody\n",
        "    from prody import *\n",
        "\n",
        "prody.confProDy(verbosity='warning')\n",
        "print(f\"ProDy Version: {prody.__version__}\")\n",
        "\n",
        "# =============================================================================\n",
        "# NMA ANALYZER CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class LinkerFlexibilityAnalyzer:\n",
        "    def __init__(self, structure_path: str, name: str = None):\n",
        "        self.name = name or Path(structure_path).stem\n",
        "        self.structure = parsePDB(structure_path)\n",
        "        self.calphas = self.structure.select('calpha')\n",
        "\n",
        "        if self.calphas is None:\n",
        "            raise ValueError(f\"No CA atoms found in {structure_path}\")\n",
        "\n",
        "        self.n_residues = self.calphas.numAtoms()\n",
        "        self.domain_indices = self._calculate_domain_indices()\n",
        "        self.linker_length = self.domain_indices['linker_length']\n",
        "\n",
        "        self._gnm = None\n",
        "        self._anm = None\n",
        "        self.results = {}\n",
        "\n",
        "    def _calculate_domain_indices(self):\n",
        "        linker_length = self.n_residues - SCFV1_LENGTH - SCFV2_LENGTH\n",
        "        if linker_length <= 0:\n",
        "            raise ValueError(f\"Invalid total length {self.n_residues}\")\n",
        "\n",
        "        return {\n",
        "            'scfv1': (0, SCFV1_LENGTH),\n",
        "            'linker': (SCFV1_LENGTH, SCFV1_LENGTH + linker_length),\n",
        "            'scfv2': (SCFV1_LENGTH + linker_length, self.n_residues),\n",
        "            'linker_length': linker_length\n",
        "        }\n",
        "\n",
        "    def run_gnm(self, cutoff=10.0, n_modes=20):\n",
        "        self._gnm = GNM(self.name)\n",
        "        self._gnm.buildKirchhoff(self.calphas, cutoff=cutoff)\n",
        "        self._gnm.calcModes(n_modes=n_modes)\n",
        "        return self._gnm\n",
        "\n",
        "    def calc_msf_gnm(self):\n",
        "        if self._gnm is None:\n",
        "            self.run_gnm()\n",
        "\n",
        "        msf = calcSqFlucts(self._gnm)\n",
        "        self.results['msf_gnm'] = msf\n",
        "        self.results['msf_gnm_mean'] = np.mean(msf)\n",
        "\n",
        "        for domain, (start, end) in [('scfv1', self.domain_indices['scfv1']),\n",
        "                                      ('scfv2', self.domain_indices['scfv2']),\n",
        "                                      ('linker', self.domain_indices['linker'])]:\n",
        "            domain_msf = msf[start:end]\n",
        "            self.results[f'{domain}_msf_mean'] = np.mean(domain_msf)\n",
        "            self.results[f'{domain}_msf_std'] = np.std(domain_msf)\n",
        "\n",
        "        return msf\n",
        "\n",
        "    def run_anm(self, cutoff=15.0, n_modes=20):\n",
        "        self._anm = ANM(self.name)\n",
        "        self._anm.buildHessian(self.calphas, cutoff=cutoff)\n",
        "        self._anm.calcModes(n_modes=n_modes)\n",
        "        return self._anm\n",
        "\n",
        "    def calc_deformability(self, n_modes=None):\n",
        "        if self._anm is None:\n",
        "            self.run_anm()\n",
        "\n",
        "        if n_modes is None:\n",
        "            n_modes = len(self._anm)\n",
        "\n",
        "        eigenvalues = self._anm.getEigvals()[:n_modes]\n",
        "        eigenvectors = self._anm.getEigvecs()[:, :n_modes]\n",
        "\n",
        "        eigenvectors_reshaped = eigenvectors.reshape(self.n_residues, 3, n_modes)\n",
        "        u_squared = np.sum(eigenvectors_reshaped**2, axis=1)\n",
        "        deformability_raw = np.sum(u_squared / eigenvalues**2, axis=1)\n",
        "\n",
        "        deformability = (deformability_raw - deformability_raw.min()) / \\\n",
        "                       (deformability_raw.max() - deformability_raw.min())\n",
        "\n",
        "        self.results['deformability'] = deformability\n",
        "        self.results['deformability_mean'] = np.mean(deformability)\n",
        "\n",
        "        for domain, (start, end) in [('linker', self.domain_indices['linker'])]:\n",
        "            domain_def = deformability[start:end]\n",
        "            self.results[f'{domain}_deformability_mean'] = np.mean(domain_def)\n",
        "\n",
        "        return deformability\n",
        "\n",
        "    def calc_stiffness(self):\n",
        "        if self._gnm is None:\n",
        "            self.run_gnm()\n",
        "\n",
        "        eigenvalues = self._gnm.getEigvals()[:10]\n",
        "        stiffness = np.mean(eigenvalues)\n",
        "        self.results['stiffness'] = stiffness\n",
        "\n",
        "        return stiffness\n",
        "\n",
        "    def calc_inter_domain_distance_fluctuation(self, n_modes=20):\n",
        "        if self._anm is None:\n",
        "            self.run_anm(n_modes=n_modes)\n",
        "\n",
        "        coords = self.calphas.getCoords()\n",
        "        scfv1_start, scfv1_end = self.domain_indices['scfv1']\n",
        "        scfv2_start, scfv2_end = self.domain_indices['scfv2']\n",
        "\n",
        "        com1_initial = np.mean(coords[scfv1_start:scfv1_end], axis=0)\n",
        "        com2_initial = np.mean(coords[scfv2_start:scfv2_end], axis=0)\n",
        "        initial_distance = np.linalg.norm(com2_initial - com1_initial)\n",
        "\n",
        "        eigenvectors = self._anm.getEigvecs()\n",
        "        eigenvalues = self._anm.getEigvals()\n",
        "        n_modes_available = min(n_modes, len(self._anm))\n",
        "\n",
        "        distance_changes = []\n",
        "        for mode_idx in range(n_modes_available):\n",
        "            mode_vector = eigenvectors[:, mode_idx].reshape(-1, 3)\n",
        "            amplitude = 5.0 / np.sqrt(eigenvalues[mode_idx])\n",
        "            displaced_coords = coords + amplitude * mode_vector\n",
        "\n",
        "            com1_displaced = np.mean(displaced_coords[scfv1_start:scfv1_end], axis=0)\n",
        "            com2_displaced = np.mean(displaced_coords[scfv2_start:scfv2_end], axis=0)\n",
        "            new_distance = np.linalg.norm(com2_displaced - com1_displaced)\n",
        "            distance_changes.append(new_distance - initial_distance)\n",
        "\n",
        "        weights = 1.0 / eigenvalues[:n_modes_available]\n",
        "        weights = weights / np.sum(weights)\n",
        "        mean_change = np.average(distance_changes, weights=weights)\n",
        "        variance = np.average((np.array(distance_changes) - mean_change)**2, weights=weights)\n",
        "        inter_domain_fluctuation = np.sqrt(variance)\n",
        "\n",
        "        self.results['inter_domain_distance_initial'] = initial_distance\n",
        "        self.results['inter_domain_fluctuation'] = inter_domain_fluctuation\n",
        "\n",
        "        return inter_domain_fluctuation\n",
        "\n",
        "    def run_full_analysis(self, gnm_cutoff=10.0, anm_cutoff=15.0, n_modes=20):\n",
        "        self.run_gnm(cutoff=gnm_cutoff, n_modes=n_modes)\n",
        "        self.calc_msf_gnm()\n",
        "        self.calc_stiffness()\n",
        "\n",
        "        self.run_anm(cutoff=anm_cutoff, n_modes=n_modes)\n",
        "        self.calc_deformability(n_modes=n_modes)\n",
        "        self.calc_inter_domain_distance_fluctuation(n_modes=n_modes)\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def get_summary_dict(self):\n",
        "        return {\n",
        "            'Filename': self.name,\n",
        "            'Linker_Length': self.linker_length,\n",
        "            'Effective_Stiffness': self.results.get('stiffness', np.nan),\n",
        "            'Inter_Domain_Fluctuation': self.results.get('inter_domain_fluctuation', np.nan),\n",
        "            'Initial_COM_Distance': self.results.get('inter_domain_distance_initial', np.nan),\n",
        "            'MSF_Linker_Mean': self.results.get('linker_msf_mean', np.nan),\n",
        "            'Deformability_Linker_Mean': self.results.get('linker_deformability_mean', np.nan),\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# RUN NMA ON ALL PREDICTIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n--- Running NMA Analysis ---\")\n",
        "\n",
        "try:\n",
        "    _ = rmsd_df\n",
        "    print(f\"✓ Found {len(rmsd_df)} structures to analyze\")\n",
        "except NameError:\n",
        "    raise RuntimeError(\"rmsd_df not found. Run Cell 2 first.\")\n",
        "\n",
        "nma_results = []\n",
        "\n",
        "for idx, row in rmsd_df.iterrows():\n",
        "    pdb_path = row['PDB_Path']\n",
        "    filename = row['Filename']\n",
        "\n",
        "    print(f\"\\n  [{idx+1}/{len(rmsd_df)}] {filename}\", end=\"\")\n",
        "\n",
        "    try:\n",
        "        analyzer = LinkerFlexibilityAnalyzer(pdb_path, name=filename.replace('.pdb', ''))\n",
        "        analyzer.run_full_analysis(gnm_cutoff=GNM_CUTOFF, anm_cutoff=ANM_CUTOFF, n_modes=N_MODES)\n",
        "\n",
        "        summary = analyzer.get_summary_dict()\n",
        "        nma_results.append(summary)\n",
        "\n",
        "        print(f\" → Stiffness: {summary['Effective_Stiffness']:.6f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" → ERROR: {e}\")\n",
        "        nma_results.append({\n",
        "            'Filename': filename.replace('.pdb', ''),\n",
        "            'Error': str(e)\n",
        "        })\n",
        "\n",
        "nma_df = pd.DataFrame(nma_results)\n",
        "\n",
        "# =============================================================================\n",
        "# DISPLAY RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"NMA RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "display_cols = ['Filename', 'Effective_Stiffness', 'Inter_Domain_Fluctuation',\n",
        "                'MSF_Linker_Mean', 'Deformability_Linker_Mean']\n",
        "display_cols = [c for c in display_cols if c in nma_df.columns]\n",
        "\n",
        "display_df = nma_df[display_cols].copy()\n",
        "for col in display_df.columns:\n",
        "    if col != 'Filename':\n",
        "        display_df[col] = display_df[col].apply(\n",
        "            lambda x: f\"{x:.4f}\" if pd.notna(x) else \"N/A\"\n",
        "        )\n",
        "\n",
        "print(display_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ Cell 3 Complete\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nData saved to: nma_df ({len(nma_df)} rows)\")\n",
        "print(\"→ Run Cell 4 for pLDDT/PAE analysis\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "183y-zD8bBF1"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# CELL 4: pLDDT & PAE ANALYSIS (From AlphaFold JSON files)\n",
        "# ================================================================================\n",
        "\n",
        "#@title **Cell 4: pLDDT & PAE Analysis** { display-mode: \"form\" }\n",
        "#@markdown ### Configuration\n",
        "#@markdown JSON files should be in the same folder as PDB files or specify separately:\n",
        "JSON_FOLDER = \"/content/predictions/\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Note:** AlphaFold2 generates JSON files with pLDDT and PAE data.\n",
        "#@markdown\n",
        "#@markdown **Requires:** Cell 2 must be run first.\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 4: pLDDT & PAE Analysis\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# ANALYSIS FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def load_alphafold_json(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "\n",
        "def calculate_domain_indices(total_length):\n",
        "    linker_length = total_length - SCFV1_LENGTH - SCFV2_LENGTH\n",
        "    if linker_length <= 0:\n",
        "        return None\n",
        "\n",
        "    return {\n",
        "        'scfv1': (0, SCFV1_LENGTH),\n",
        "        'linker': (SCFV1_LENGTH, SCFV1_LENGTH + linker_length),\n",
        "        'scfv2': (SCFV1_LENGTH + linker_length, total_length),\n",
        "        'linker_length': linker_length,\n",
        "    }\n",
        "\n",
        "\n",
        "def extract_plddt_metrics(plddt, indices):\n",
        "    plddt_array = np.array(plddt)\n",
        "\n",
        "    linker_plddt = plddt_array[indices['linker'][0]:indices['linker'][1]]\n",
        "    scfv1_plddt = plddt_array[indices['scfv1'][0]:indices['scfv1'][1]]\n",
        "    scfv2_plddt = plddt_array[indices['scfv2'][0]:indices['scfv2'][1]]\n",
        "\n",
        "    return {\n",
        "        'pLDDT_Global_Mean': float(np.mean(plddt_array)),\n",
        "        'pLDDT_scFv1_Mean': float(np.mean(scfv1_plddt)),\n",
        "        'pLDDT_scFv2_Mean': float(np.mean(scfv2_plddt)),\n",
        "        'pLDDT_Linker_Mean': float(np.mean(linker_plddt)),\n",
        "        'pLDDT_Linker_Min': float(np.min(linker_plddt)),\n",
        "    }\n",
        "\n",
        "\n",
        "def extract_pae_metrics(pae, indices):\n",
        "    pae_array = np.array(pae)\n",
        "\n",
        "    scfv1_s, scfv1_e = indices['scfv1']\n",
        "    scfv2_s, scfv2_e = indices['scfv2']\n",
        "    linker_s, linker_e = indices['linker']\n",
        "\n",
        "    # Inter-domain PAE\n",
        "    pae_12 = pae_array[scfv1_s:scfv1_e, scfv2_s:scfv2_e]\n",
        "    pae_21 = pae_array[scfv2_s:scfv2_e, scfv1_s:scfv1_e]\n",
        "    inter_domain = (np.mean(pae_12) + np.mean(pae_21)) / 2\n",
        "\n",
        "    # Linker stability\n",
        "    linker_to_1 = np.mean(pae_array[linker_s:linker_e, scfv1_s:scfv1_e])\n",
        "    linker_to_2 = np.mean(pae_array[linker_s:linker_e, scfv2_s:scfv2_e])\n",
        "\n",
        "    return {\n",
        "        'PAE_Inter_Domain': float(inter_domain),\n",
        "        'PAE_Linker_to_scFv1': float(linker_to_1),\n",
        "        'PAE_Linker_to_scFv2': float(linker_to_2),\n",
        "        'PAE_Linker_Stability': float((linker_to_1 + linker_to_2) / 2),\n",
        "    }\n",
        "\n",
        "\n",
        "def analyze_json_file(json_path, name=None):\n",
        "    data = load_alphafold_json(json_path)\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    plddt = data.get('plddt', [])\n",
        "    if not plddt:\n",
        "        return None\n",
        "\n",
        "    total_length = len(plddt)\n",
        "    indices = calculate_domain_indices(total_length)\n",
        "    if indices is None:\n",
        "        return None\n",
        "\n",
        "    results = {\n",
        "        'Filename': name or Path(json_path).stem,\n",
        "        'Total_Length': total_length,\n",
        "        'pTM_Score': data.get('ptm', data.get('pTM', data.get('ranking_confidence', np.nan))),\n",
        "    }\n",
        "\n",
        "    results.update(extract_plddt_metrics(plddt, indices))\n",
        "\n",
        "    pae = data.get('pae', data.get('predicted_aligned_error', None))\n",
        "    if pae is not None:\n",
        "        results.update(extract_pae_metrics(pae, indices))\n",
        "\n",
        "    return results\n",
        "\n",
        "# =============================================================================\n",
        "# FIND AND ANALYZE JSON FILES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n--- Finding JSON Files ---\")\n",
        "\n",
        "json_folder = Path(JSON_FOLDER)\n",
        "json_files = list(json_folder.glob(\"*.json\"))\n",
        "\n",
        "# Also try common AlphaFold JSON naming patterns\n",
        "if not json_files:\n",
        "    json_files = list(json_folder.glob(\"*_scores*.json\"))\n",
        "if not json_files:\n",
        "    json_files = list(json_folder.glob(\"ranking_debug.json\"))\n",
        "\n",
        "print(f\"Found {len(json_files)} JSON files\")\n",
        "\n",
        "# If no JSON files, try to extract pLDDT from B-factor in PDB files\n",
        "USE_PDB_BFACTOR = len(json_files) == 0\n",
        "\n",
        "if USE_PDB_BFACTOR:\n",
        "    print(\"\\n⚠️ No JSON files found. Extracting pLDDT from PDB B-factors...\")\n",
        "\n",
        "    plddt_results = []\n",
        "\n",
        "    for idx, row in rmsd_df.iterrows():\n",
        "        pdb_path = row['PDB_Path']\n",
        "        filename = row['Filename']\n",
        "\n",
        "        print(f\"\\n  [{idx+1}/{len(rmsd_df)}] {filename}\", end=\"\")\n",
        "\n",
        "        try:\n",
        "            parser = PDBParser(QUIET=True)\n",
        "            structure = parser.get_structure('pdb', pdb_path)\n",
        "\n",
        "            # Extract B-factors (pLDDT in AlphaFold PDBs)\n",
        "            bfactors = []\n",
        "            for model in structure:\n",
        "                for chain in model:\n",
        "                    for residue in chain:\n",
        "                        if is_aa(residue, standard=True) and 'CA' in residue:\n",
        "                            bfactors.append(residue['CA'].get_bfactor())\n",
        "\n",
        "            if len(bfactors) > 0:\n",
        "                total_length = len(bfactors)\n",
        "                indices = calculate_domain_indices(total_length)\n",
        "\n",
        "                if indices:\n",
        "                    plddt_array = np.array(bfactors)\n",
        "                    linker_plddt = plddt_array[indices['linker'][0]:indices['linker'][1]]\n",
        "\n",
        "                    result = {\n",
        "                        'Filename': filename.replace('.pdb', ''),\n",
        "                        'pLDDT_Global_Mean': np.mean(plddt_array),\n",
        "                        'pLDDT_Linker_Mean': np.mean(linker_plddt),\n",
        "                        'pLDDT_Linker_Min': np.min(linker_plddt),\n",
        "                    }\n",
        "                    plddt_results.append(result)\n",
        "                    print(f\" → pLDDT: {result['pLDDT_Global_Mean']:.1f}\")\n",
        "                else:\n",
        "                    print(f\" → Invalid length\")\n",
        "            else:\n",
        "                print(f\" → No B-factors\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" → ERROR: {e}\")\n",
        "\n",
        "    plddt_df = pd.DataFrame(plddt_results) if plddt_results else pd.DataFrame()\n",
        "\n",
        "else:\n",
        "    print(\"\\n--- Analyzing JSON Files ---\")\n",
        "\n",
        "    plddt_results = []\n",
        "\n",
        "    for idx, json_file in enumerate(json_files, 1):\n",
        "        print(f\"\\n  [{idx}/{len(json_files)}] {json_file.name}\", end=\"\")\n",
        "\n",
        "        result = analyze_json_file(str(json_file), name=json_file.stem)\n",
        "\n",
        "        if result:\n",
        "            plddt_results.append(result)\n",
        "            ptm = result.get('pTM_Score', np.nan)\n",
        "            ptm_str = f\"{ptm:.3f}\" if pd.notna(ptm) else \"N/A\"\n",
        "            print(f\" → pTM: {ptm_str}, pLDDT: {result['pLDDT_Global_Mean']:.1f}\")\n",
        "        else:\n",
        "            print(f\" → Failed to parse\")\n",
        "\n",
        "    plddt_df = pd.DataFrame(plddt_results) if plddt_results else pd.DataFrame()\n",
        "\n",
        "# =============================================================================\n",
        "# DISPLAY RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"pLDDT/PAE RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if len(plddt_df) > 0:\n",
        "    display_cols = ['Filename', 'pTM_Score', 'pLDDT_Global_Mean', 'pLDDT_Linker_Mean',\n",
        "                   'PAE_Inter_Domain', 'PAE_Linker_Stability']\n",
        "    display_cols = [c for c in display_cols if c in plddt_df.columns]\n",
        "\n",
        "    display_df = plddt_df[display_cols].copy()\n",
        "    for col in display_df.columns:\n",
        "        if col != 'Filename':\n",
        "            display_df[col] = display_df[col].apply(\n",
        "                lambda x: f\"{x:.2f}\" if pd.notna(x) else \"N/A\"\n",
        "            )\n",
        "\n",
        "    print(display_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"⚠️ No pLDDT/PAE data available\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ Cell 4 Complete\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nData saved to: plddt_df ({len(plddt_df)} rows)\")\n",
        "print(\"→ Run Cell 5 for Antigen Distance analysis\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaUcqzbfbBF1"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# CELL 5: ANTIGEN DISTANCE MEASUREMENT (130Å Target)\n",
        "# ================================================================================\n",
        "\n",
        "#@title **Cell 5: Antigen Distance (130Å Target)** { display-mode: \"form\" }\n",
        "#@markdown ### Configuration\n",
        "ANTIGEN_COMPLEX_PATH = \"/content/Include_antigen_with_perfect_distance.pdb\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Antigen Distance Settings\n",
        "CHAIN_B_RESNUM = 102  #@param {type:\"integer\"}\n",
        "CHAIN_D_RESNUM = 652  #@param {type:\"integer\"}\n",
        "TARGET_DISTANCE = 130.0  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Requires:** Cell 2 must be run first.\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 5: Antigen Distance Measurement\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nTarget: {TARGET_DISTANCE} Å (CD3e-HER2 membrane distance)\")\n",
        "\n",
        "# =============================================================================\n",
        "# VALIDATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n--- Validation ---\")\n",
        "\n",
        "if not Path(ANTIGEN_COMPLEX_PATH).exists():\n",
        "    print(f\"⚠️ Antigen complex not found: {ANTIGEN_COMPLEX_PATH}\")\n",
        "    print(\"  Antigen distance measurement will be skipped.\")\n",
        "    ANTIGEN_AVAILABLE = False\n",
        "else:\n",
        "    print(f\"✓ Antigen complex found\")\n",
        "    ANTIGEN_AVAILABLE = True\n",
        "\n",
        "# =============================================================================\n",
        "# LOAD ANTIGEN-ANTIBODY COMPLEX\n",
        "# =============================================================================\n",
        "\n",
        "if ANTIGEN_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"LOADING ANTIGEN-ANTIBODY COMPLEX\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    parser = PDBParser(QUIET=True)\n",
        "    antigen_complex = parser.get_structure('antigen_complex', ANTIGEN_COMPLEX_PATH)\n",
        "\n",
        "    chain_A_residues = []\n",
        "    chain_B_residues = []\n",
        "    chain_C_residues = []\n",
        "    chain_D_residues = []\n",
        "\n",
        "    for model in antigen_complex:\n",
        "        for chain in model:\n",
        "            chain_id = chain.get_id()\n",
        "            for residue in chain:\n",
        "                if is_aa(residue, standard=True):\n",
        "                    if chain_id == 'A':\n",
        "                        chain_A_residues.append(residue)\n",
        "                    elif chain_id == 'B':\n",
        "                        chain_B_residues.append(residue)\n",
        "                    elif chain_id == 'C':\n",
        "                        chain_C_residues.append(residue)\n",
        "                    elif chain_id == 'D':\n",
        "                        chain_D_residues.append(residue)\n",
        "\n",
        "    print(f\"  Chain A (scFv1): {len(chain_A_residues)} residues\")\n",
        "    print(f\"  Chain B (CD3e): {len(chain_B_residues)} residues\")\n",
        "    print(f\"  Chain C (scFv2): {len(chain_C_residues)} residues\")\n",
        "    print(f\"  Chain D (HER2): {len(chain_D_residues)} residues\")\n",
        "\n",
        "    chain_A_ca = get_ca_atoms(chain_A_residues)\n",
        "    chain_C_ca = get_ca_atoms(chain_C_residues)\n",
        "\n",
        "    # Find target residues\n",
        "    chain_B_target_ca = None\n",
        "    chain_D_target_ca = None\n",
        "\n",
        "    for model in antigen_complex:\n",
        "        if 'B' in [c.get_id() for c in model]:\n",
        "            for residue in model['B']:\n",
        "                if residue.get_id()[1] == CHAIN_B_RESNUM and 'CA' in residue:\n",
        "                    chain_B_target_ca = residue['CA']\n",
        "                    break\n",
        "\n",
        "        if 'D' in [c.get_id() for c in model]:\n",
        "            for residue in model['D']:\n",
        "                if residue.get_id()[1] == CHAIN_D_RESNUM and 'CA' in residue:\n",
        "                    chain_D_target_ca = residue['CA']\n",
        "                    break\n",
        "\n",
        "    if chain_B_target_ca and chain_D_target_ca:\n",
        "        original_distance = chain_B_target_ca - chain_D_target_ca\n",
        "        print(f\"\\n  ✓ Target residues found\")\n",
        "        print(f\"  Original complex distance: {original_distance:.2f} Å\")\n",
        "    else:\n",
        "        print(f\"  ⚠️ Could not find target residues\")\n",
        "        ANTIGEN_AVAILABLE = False\n",
        "\n",
        "# =============================================================================\n",
        "# MEASURE ANTIGEN DISTANCE FOR EACH PDB\n",
        "# =============================================================================\n",
        "\n",
        "if ANTIGEN_AVAILABLE:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"MEASURING ANTIGEN DISTANCES\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    antigen_results = []\n",
        "\n",
        "    for idx, row in rmsd_df.iterrows():\n",
        "        pdb_path = row['PDB_Path']\n",
        "        filename = row['Filename']\n",
        "\n",
        "        print(f\"\\n  [{idx+1}/{len(rmsd_df)}] {filename}\", end=\"\")\n",
        "\n",
        "        try:\n",
        "            parser = PDBParser(QUIET=True)\n",
        "            af_structure = parser.get_structure('af', pdb_path)\n",
        "            af_residues = extract_residues(af_structure)\n",
        "\n",
        "            af_scfv1_ca = get_ca_atoms(af_residues[:SCFV1_LENGTH])\n",
        "            af_scfv2_ca = get_ca_atoms(af_residues[-SCFV2_LENGTH:])\n",
        "\n",
        "            if len(af_scfv1_ca) != len(chain_A_ca) or len(af_scfv2_ca) != len(chain_C_ca):\n",
        "                print(f\" → Atom mismatch\")\n",
        "                continue\n",
        "\n",
        "            # Superimpose Chain A → AlphaFold scFv1\n",
        "            sup1 = Superimposer()\n",
        "            sup1.set_atoms(af_scfv1_ca, chain_A_ca)\n",
        "\n",
        "            chain_B_coord = chain_B_target_ca.get_coord().copy()\n",
        "            chain_B_transformed = np.dot(chain_B_coord, sup1.rotran[0].T) + sup1.rotran[1]\n",
        "\n",
        "            # Superimpose Chain C → AlphaFold scFv2\n",
        "            sup2 = Superimposer()\n",
        "            sup2.set_atoms(af_scfv2_ca, chain_C_ca)\n",
        "\n",
        "            chain_D_coord = chain_D_target_ca.get_coord().copy()\n",
        "            chain_D_transformed = np.dot(chain_D_coord, sup2.rotran[0].T) + sup2.rotran[1]\n",
        "\n",
        "            # Calculate distance\n",
        "            antigen_distance = np.linalg.norm(chain_B_transformed - chain_D_transformed)\n",
        "            distance_from_target = antigen_distance - TARGET_DISTANCE\n",
        "\n",
        "            print(f\" → {antigen_distance:.2f} Å (Δ: {distance_from_target:+.2f} Å)\")\n",
        "\n",
        "            antigen_results.append({\n",
        "                'Filename': filename.replace('.pdb', ''),\n",
        "                'Antigen_Distance': antigen_distance,\n",
        "                'Distance_From_Target': distance_from_target,\n",
        "                'Abs_Error': abs(distance_from_target),\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" → ERROR: {e}\")\n",
        "\n",
        "    antigen_df = pd.DataFrame(antigen_results)\n",
        "else:\n",
        "    antigen_df = pd.DataFrame()\n",
        "\n",
        "# =============================================================================\n",
        "# DISPLAY RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANTIGEN DISTANCE RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if len(antigen_df) > 0:\n",
        "    display_df = antigen_df.copy()\n",
        "    display_df['Antigen_Distance'] = display_df['Antigen_Distance'].apply(lambda x: f\"{x:.2f}\")\n",
        "    display_df['Distance_From_Target'] = display_df['Distance_From_Target'].apply(lambda x: f\"{x:+.2f}\")\n",
        "\n",
        "    print(f\"\\n(Target: {TARGET_DISTANCE} Å)\")\n",
        "    print(display_df[['Filename', 'Antigen_Distance', 'Distance_From_Target']].to_string(index=False))\n",
        "\n",
        "    # Best candidate\n",
        "    best_idx = antigen_df['Abs_Error'].idxmin()\n",
        "    best = antigen_df.loc[best_idx]\n",
        "    print(f\"\\n★ Closest to target: {best['Filename']}\")\n",
        "    print(f\"  Distance: {best['Antigen_Distance']:.2f} Å (Δ: {best['Distance_From_Target']:+.2f} Å)\")\n",
        "else:\n",
        "    print(\"⚠️ No antigen distance data available\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ Cell 5 Complete\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nData saved to: antigen_df ({len(antigen_df)} rows)\")\n",
        "print(\"→ Run Cell 6 for Final Summary\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdHRKeKrbBF2"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# CELL 6: FINAL SUMMARY - ALL METRICS TABLE\n",
        "# ================================================================================\n",
        "\n",
        "#@title **Cell 6: Final Summary Table** { display-mode: \"form\" }\n",
        "#@markdown Combines all analysis results into one comprehensive table.\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CELL 6: Final Summary - All Metrics\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# MERGE ALL DATAFRAMES\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n--- Collecting Results ---\")\n",
        "\n",
        "# Start with RMSD results\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "try:\n",
        "    final_df = rmsd_df[['Filename', 'Final_RMSD', 'scFv1_RMSD', 'scFv2_RMSD',\n",
        "                        'Linker_Length', 'Best_Alignment', 'PDB_Path']].copy()\n",
        "    final_df['Jobname'] = final_df['Filename'].apply(lambda x: x.replace('.pdb', ''))\n",
        "    print(f\"  ✓ RMSD: {len(final_df)} entries\")\n",
        "except Exception as e:\n",
        "    print(f\"  ✗ RMSD data error: {e}\")\n",
        "\n",
        "# Merge NMA results\n",
        "try:\n",
        "    if 'nma_df' in dir() and len(nma_df) > 0:\n",
        "        nma_merge = nma_df.copy()\n",
        "        nma_merge['Jobname'] = nma_merge['Filename'].apply(lambda x: x.replace('.pdb', ''))\n",
        "        nma_cols = ['Jobname', 'Effective_Stiffness', 'Inter_Domain_Fluctuation',\n",
        "                   'Initial_COM_Distance', 'MSF_Linker_Mean', 'Deformability_Linker_Mean']\n",
        "        nma_cols = [c for c in nma_cols if c in nma_merge.columns]\n",
        "        final_df = final_df.merge(nma_merge[nma_cols], on='Jobname', how='left')\n",
        "        print(f\"  ✓ NMA: merged\")\n",
        "except Exception as e:\n",
        "    print(f\"  ⚠️ NMA merge error: {e}\")\n",
        "\n",
        "# Merge pLDDT/PAE results\n",
        "try:\n",
        "    if 'plddt_df' in dir() and len(plddt_df) > 0:\n",
        "        plddt_merge = plddt_df.copy()\n",
        "        plddt_merge['Jobname'] = plddt_merge['Filename'].apply(lambda x: x.replace('.pdb', ''))\n",
        "        plddt_cols = ['Jobname', 'pTM_Score', 'pLDDT_Global_Mean', 'pLDDT_scFv1_Mean',\n",
        "                     'pLDDT_scFv2_Mean', 'pLDDT_Linker_Mean', 'pLDDT_Linker_Min',\n",
        "                     'PAE_Inter_Domain', 'PAE_Linker_to_scFv1', 'PAE_Linker_to_scFv2',\n",
        "                     'PAE_Linker_Stability']\n",
        "        plddt_cols = [c for c in plddt_cols if c in plddt_merge.columns]\n",
        "        final_df = final_df.merge(plddt_merge[plddt_cols], on='Jobname', how='left')\n",
        "        print(f\"  ✓ pLDDT/PAE: merged\")\n",
        "except Exception as e:\n",
        "    print(f\"  ⚠️ pLDDT/PAE merge error: {e}\")\n",
        "\n",
        "# Merge Antigen Distance results\n",
        "try:\n",
        "    if 'antigen_df' in dir() and len(antigen_df) > 0:\n",
        "        antigen_merge = antigen_df.copy()\n",
        "        antigen_merge['Jobname'] = antigen_merge['Filename'].apply(lambda x: x.replace('.pdb', ''))\n",
        "        antigen_cols = ['Jobname', 'Antigen_Distance', 'Distance_From_Target']\n",
        "        final_df = final_df.merge(antigen_merge[antigen_cols], on='Jobname', how='left')\n",
        "        print(f\"  ✓ Antigen Distance: merged\")\n",
        "except Exception as e:\n",
        "    print(f\"  ⚠️ Antigen distance merge error: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# ORGANIZE COLUMNS\n",
        "# =============================================================================\n",
        "\n",
        "# Define column order for clean display\n",
        "column_order = [\n",
        "    # Identification\n",
        "    'Jobname',\n",
        "\n",
        "    # RMSD metrics\n",
        "    'Final_RMSD',\n",
        "    'scFv1_RMSD',\n",
        "    'scFv2_RMSD',\n",
        "    'Best_Alignment',\n",
        "    'Linker_Length',\n",
        "\n",
        "    # Antigen Distance (130Å target)\n",
        "    'Antigen_Distance',\n",
        "    'Distance_From_Target',\n",
        "\n",
        "    # pLDDT metrics\n",
        "    'pTM_Score',\n",
        "    'pLDDT_Global_Mean',\n",
        "    'pLDDT_scFv1_Mean',\n",
        "    'pLDDT_scFv2_Mean',\n",
        "    'pLDDT_Linker_Mean',\n",
        "    'pLDDT_Linker_Min',\n",
        "\n",
        "    # PAE metrics\n",
        "    'PAE_Inter_Domain',\n",
        "    'PAE_Linker_to_scFv1',\n",
        "    'PAE_Linker_to_scFv2',\n",
        "    'PAE_Linker_Stability',\n",
        "\n",
        "    # NMA metrics\n",
        "    'Effective_Stiffness',\n",
        "    'Inter_Domain_Fluctuation',\n",
        "    'Initial_COM_Distance',\n",
        "    'MSF_Linker_Mean',\n",
        "    'Deformability_Linker_Mean',\n",
        "]\n",
        "\n",
        "# Filter to available columns\n",
        "available_cols = [c for c in column_order if c in final_df.columns]\n",
        "final_df = final_df[available_cols]\n",
        "\n",
        "# =============================================================================\n",
        "# DISPLAY FULL TABLE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ALL METRICS TABLE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Set pandas display options for full view\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.float_format', lambda x: f'{x:.4f}' if pd.notna(x) else 'NaN')\n",
        "\n",
        "print(f\"\\nTotal entries: {len(final_df)}\")\n",
        "print(f\"Total columns: {len(final_df.columns)}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Display the full dataframe\n",
        "print(final_df.to_string(index=False))\n",
        "\n",
        "# =============================================================================\n",
        "# COLUMN DESCRIPTIONS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COLUMN DESCRIPTIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "descriptions = {\n",
        "    'Jobname': 'Sample name',\n",
        "    'Final_RMSD': 'RMSD vs Reference (Å) - lower is more similar',\n",
        "    'scFv1_RMSD': 'scFv1 domain RMSD (Å)',\n",
        "    'scFv2_RMSD': 'scFv2 domain RMSD (Å)',\n",
        "    'Best_Alignment': 'Which domain was used for alignment',\n",
        "    'Linker_Length': 'Linker length (residues)',\n",
        "    'Antigen_Distance': 'CD3e-HER2 membrane distance (Å) - target: 130Å',\n",
        "    'Distance_From_Target': 'Difference from 130Å target (Å)',\n",
        "    'pTM_Score': 'Predicted TM score (0-1) - higher is better',\n",
        "    'pLDDT_Global_Mean': 'Global pLDDT (0-100) - higher is better',\n",
        "    'pLDDT_scFv1_Mean': 'scFv1 pLDDT mean',\n",
        "    'pLDDT_scFv2_Mean': 'scFv2 pLDDT mean',\n",
        "    'pLDDT_Linker_Mean': 'Linker pLDDT mean - higher is more confident',\n",
        "    'pLDDT_Linker_Min': 'Linker pLDDT minimum',\n",
        "    'PAE_Inter_Domain': 'Inter-domain PAE (Å) - lower is better',\n",
        "    'PAE_Linker_to_scFv1': 'Linker to scFv1 PAE (Å)',\n",
        "    'PAE_Linker_to_scFv2': 'Linker to scFv2 PAE (Å)',\n",
        "    'PAE_Linker_Stability': 'Average linker attachment PAE - lower is better',\n",
        "    'Effective_Stiffness': 'GNM stiffness (eigenvalue mean) - higher is more rigid',\n",
        "    'Inter_Domain_Fluctuation': 'Domain distance fluctuation (Å) - lower is more rigid',\n",
        "    'Initial_COM_Distance': 'Initial scFv1-scFv2 COM distance (Å)',\n",
        "    'MSF_Linker_Mean': 'Linker mean square fluctuation - lower is more rigid',\n",
        "    'Deformability_Linker_Mean': 'Linker deformability (0-1) - lower is more rigid',\n",
        "}\n",
        "\n",
        "for col in available_cols:\n",
        "    if col in descriptions:\n",
        "        print(f\"  • {col}: {descriptions[col]}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SAVE TO CSV (optional)\n",
        "# =============================================================================\n",
        "\n",
        "csv_path = '/content/final_analysis_results.csv'\n",
        "final_df.to_csv(csv_path, index=False)\n",
        "print(f\"\\n✓ Saved to: {csv_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# SUMMARY STATISTICS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "numeric_cols = final_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "for col in numeric_cols:\n",
        "    if final_df[col].notna().any():\n",
        "        vals = final_df[col].dropna()\n",
        "        print(f\"\\n  {col}:\")\n",
        "        print(f\"    Mean: {vals.mean():.4f}\")\n",
        "        print(f\"    Std:  {vals.std():.4f}\")\n",
        "        print(f\"    Min:  {vals.min():.4f}\")\n",
        "        print(f\"    Max:  {vals.max():.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"✓ ANALYSIS COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nDataFrame 'final_df' contains all metrics.\")\n",
        "print(\"Use final_df.to_clipboard() to copy to Excel.\")\n",
        "print(\"=\" * 70)\n"
      ]
    }
  ]
}